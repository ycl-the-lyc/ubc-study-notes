#import "../lib.typ": *
#show: setup.with(
  title: [MATH 256 _Differential Equations_],
  author: "Yecheng Liang",
)

#set math.vec(delim: "[")
#set math.mat(delim: "[")

#let oL = math.op[L]

= Differential Equations
#definition(title: [Differential Equation])[
  An equation that defines a function by giving a relationship between the function and its derivative.
]

#example[
  $
    y' + y = x.
  $
]

Integration is solving a trivial differential equation.

Given a first-order, linear differential equation, $dv(y, x) = a y$, a reasonable guess is $y = A e^(a x)$.
We can take any constant $A$ because the equation is linear.

== Seperable Equations Method
For non-linear differential equations, we would manipulate the equation so one side is expressed by $y$, the other by $x$ and $dd(x)$.
Then, integrating both sides gives us a relationship between $x$ and $y$.

#example[
  $
              dv(y, x) & = a y \
             dd(y) / y & = a dd(x) \
    integral dd(y) / y & = a integral dd(x) + C \
             ln abs(y) & = a x + C \
                     y & = e^(ln(abs(y))) \
                       & = e^(a x + C) \
                       & = e^c e^(a x) \
                       & = A e^(a x).
  $
]

== Integrating Factor Method
With a linear first-order equation, we can forcibly express it by only $x$.

Let $oL$ be an operator such that
$
  oL y & = (dv(, x) + p(x)) y \
       & = dv(y, x) + p(x) y \
       & = g(x).
$
So long as $p(x), g(x)$ are continuous, a solution exists.
And, if $oL y = 0$, we say the equation is homogeneous.

Let $F(x)$ be the _integrating factor_ such that
$
  F(x) dv(y, x) + F(x) p(x) y & = dv(, x) [F(x) y].
$
From the equatoion above we can see that, if we differentiate $F(x)$, we get itself multiplied by $p(x)$, looks much like our guess of exponential before.
Hence,
$
  F(x) & = e^(integral p(x) dd(x)).
$

Multiply $oL y$ by $F(x)$,
$
  e^(integral p(x) dd(x)) dv(y, x) + e^(integral p(x) dd(x)) p(x) y & = e^(integral p(x) dd(x)) g(x)
$
Notice that the LHS is differential of a product.
$
  dv(, x) [e^(integral p(x) dd(x)) y] & = e^(integral p(x) dd(x)) g(x) \
            e^(integral p(x) dd(x)) y & = integral e^(integral p(x) dd(x)) g(x) dd(x) + C \
                                    y & = e^(-integral p(x) dd(x)) (integral e^(integral p(x) dd(x)) g(x) dd(x) + C).
$

#problem[
  Solve
  $
    cases(
      oL y = y' + y = x,
      y(0) = 1
    )
  $

  #solution[
    Using the integral factor form, let
    $
       p(x) & = 1 \
       y(x) & = x \
      y'(x) & = 1.
    $
    Thus, we find the integrating factor to be
    $
      F(x) & = e^(integral p(x) dd(x)) \
           & = e^x.
    $
    Then, transform the equation by multiplying $F(x) = e^x$ to both sides.
    $
      e^x y' + e^x y & = [e^x y]' \
                     & = x e^x.
    $
    Notice that the LHS is differential of a product, undo the chain rule, we get
    $
      e^x y & = e^x x - e^x + C.
    $
    Don't forget the $C$ generated by the integrating both sides.

    Move the factor of integration to the RHS,
    $
      y & = x - 1 + C e^(-x)
    $
    Plug in $y(0) = 1$,
    $
      y(x) = x - 1 + 2e^(-x).
    $
  ]
]

#problem[
  Solve
  $
    oL y & = y' + y = sin(x).
  $

  #solution[
    Recall Euler's Equation,
    $
      e^(i x) = cos(x) + i sin(x).
    $

    Similar to the previous problem,
    $
          F(x) & = e^x oL y \
               & = [e^x y]' \
               & = e^x sin(x) \
      [e^x y]' & = Im e^((1 + i)x).
    $
    Integrate both sides,
    $
      e^x y & = Im e^((1 + i)x) / (1 + i) + C.
    $
    Turn the fraction term of RHS into proper form,
    $
      e^((1 + i)x) / (1 + i) & = (e^((1 + i)x) (1 - i)) / ((1 + i) (1 - i)) \
                             & = (e^((1 + i)x) (1 - i)) / 2.
    $
    Continue with the factor of integration method,
    $
      y & = Im (e^((1 + i)x) (1 - i) e^(-x)) / 2 + C e^(-x) \
        & = Im (e^(i x) (1 - i)) / 2 + C e^(-x) \
        & = Im ((cos(x) + i sin(x)) (1 - i)) / 2 + C e^(-x) \
        & = Im ((cos(x) - i^2 sin(x)) + (i sin(x) - i cos(x))) / 2 + C e^(-x) \
        & = Im ((cos(x) + sin(x)) + i (sin(x) - cos(x))) / 2 + C e^(-x) \
        & = (sin(x) - cos(x)) / 2 + C e^(-x).
    $
    No particular solution.
  ]
]

== Undetermined Coefficient Method
For a homogeneous linear equatoion, we can guess a particular solution, $y_p$.
- If $g(x) = x^n$, then $y_p = a_n x^n + a_(n-1) x^(n-1) + ... + a_1 x + a_0$.
- If $g(x) = e^(a x)$, then $y_p = A e^(a x)$.
- If $g(x) = sin(x) "or" cos(x)$, then $y_p = A cos(x) + B sin(x)$.
The guesses are linear combinations of all possible derivatives of $g(x)$.

The particular solution still carries undetermined coefficients.
Assume this $y_p$ to transform $oL y$.

= Higher Order ODEs

== Linear Second-order ODEs
Redefine the operator $oL$:
$
  oL y & := y'' + p(x) y' + q(x) y = g(x).
$
If $g(x) = 0$, we say the equation is homogeneous.

Such equations are common in superposition of waves and such.

== Constant Coefficient Equations
If $g(x) = 0$ and the coefficients are constant, like
$
  oL y = a y'' + b y' + c y = 0,
$
then,
$
     y & = e^(r x) \
  oL y & = (a r^2 + b r + c) e^(r x) = 0.
$

Since $e^(r x) eq.not 0$, solving the equation is the same as solving the contained quadratic equation.
If $Delta < 0$, then the roots are complex,
$
  r_(1, 2) & = lambda plus.minus i mu \
      y(x) & = e^(r x) (A cos(mu x) + B sin(mu x))
$

#problem[
  A stone thrown vertically up at speed $v_0$ at height $h$.
  Express its displacement as a function of $t$.

  #solution[
    $
                     y'' & = -g \
      integral y'' dd(t) & = integral -g dd(t) \
                      y' & = -g t + C \
                   y'(0) & = v_0 = C \
       integral y' dd(t) & = integral -g t + v_0 dd(t) \
                       y & = v_0 t - 1/2 g t^2 + D \
                    y(0) & = h = D \
                    y(t) & = h + v_0 t - 1/2 g t^2.
    $
  ]
]

== Initial Value Problem
With similar setup to the previous problem, but the coefficients may not be constants.

Given $oL y = 0$ and initial conditions $y(x_0) = y_0, y'(x_0) = v_0$, let $y_1(x), y_2(x)$ be two solutions to $oL y = 0$.
Since $oL$ is a linear operation, its solution is also linear.
$
     y(x) & = C_1 y_1(x) + C_2 y_2(x) \
   y(x_0) & = C_1 y_1(x_0) + C_2 y_2(x_0) \
          & = y_0 \
  y'(x_0) & = C_1 y'_1(x_0) + C_2 y'_2(x_0) \
          & = v_0.
$
This can be written as
$
  underbrace(mat(y_1(x_0), y_2(x_0); y'_1(x_0), y'_2(x_0)), A) mat(C_1; C_2) = mat(y_0; v_0).
$

For it to be solved as having constant coefficients, $det(A) eq.not 0$, i.e. $A^(-1)$ must exist.

#definition(title: [Wronsian Function])[
  Given $y_1(x), y_2(x)$,
  $
    W(y_1, y_2)(x) := mdet(y_1(x), y_2(x); y'_1(x), y'_2(x)).
  $
]

#definition(title: [Fundamental Set of Solutions])[
  Given $oL y = y'' + p(x) y' + q(x) y = 0$, the pair ${y_1(x), y_2(x)}$ is a set of fundamental solutions on an interval $I$, provided that $W(Y_1, y_2)(x_0)$ where $x_0 in I$.
]

So, an initial value problem has solution if $W(y_1, y_2)(x_0) eq.not 0$.

== Linear Dependency of Functions
Given two functions $f(x), g(x)$ which are valid on interval $I$, they are linearly dependent on $I$ if there exists non-zero $c_1, c_2$ such that
$
  c_1 y(x) + c_2 g(x) = 0.
$

If $y(x) = C_1 y_1(x) + C_2 y_2(x)$, then ${y_1, y_2}$ is a set of fundamental solutions.

== Simple Harmonic Motion
Second-order differential equations are common in problems where contributing factors also produce hindrances, like spring-mass and inductor-capacitor systems.

#example[
  Given a spring hanging a mass,
  $
    m dot.double(x) & = - m g - k x - beta dot(x) \
    m dot.double(x) + underbrace(beta dot(x), #[damping]) + underbrace(k x, #[energy\ storage]) = underbrace(- m g, #[forcing])
  $
]

=== Free Undamped Oscillation
Ignore external influence ("free") and damping.

#example[
  $
                        g & = 0 \
                     beta & = 0 \
    m dot.double(x) + k x & = 0.
  $
]

=== Free Damped Oscillation
There is still no external forcing.

#example[
  $
                                      g & = 0 \
    m dot.double(x) + beta dot(x) + k x & = 0.
  $

  See this as a constant coefficient equation,
  $
                  x(t) & = e^(r t) \
    m r^2 + beta r + k & = 0 \
                 Delta & = beta^2 + 4 m k \
                     r & = (-beta plus.minus Delta) / (2m).
  $

  If $Delta < 0$, then
  $
    r_(1, 2) & = - beta / (2m) plus.minus i sqrt(4 m k - beta^2) / (2m) \
             & = - beta / (2m) plus.minus omega_1
  $
  where
  $
    omega_1 & = sqrt((4 m k - beta^2) / (4m^2)) \
            & = sqrt(k/m - beta^2 / (4m^2)) \
            & = sqrt(k/m (1 - beta^2 / (4 m k))) \
            & = sqrt(k/m) sqrt(1 - beta^2 / (4 m k)) \
            & = omega_0 sqrt(1 - beta^2 / (4 m k)).
  $

  Substitute it back, plus Euler's equation,
  $
    x(t) = e^(- beta / (2m) t) [A cos(omega_1) t + B sin(omega_1) t].
  $

  If $Delta > 0$, then solve for $r_1, r_2$ as usual.
  Since $beta, m, k > 0$, the roots will be negative.
  $
    x(t) = A e^(r_1 t) + B e^(r_2 t)
  $
  which is an overdamp.

  If $Delta = 0$, then
  $
    beta^2 - 4 m k & = 0 \
              beta & = 2 sqrt(m k) \
                 r & = - beta / (2 m k) \
              x(t) & = e^(- beta / (2m)) [A + B t]
  $
  which is a critcal damp.
]
